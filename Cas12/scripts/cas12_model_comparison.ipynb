{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/Cas12')"
      ],
      "metadata": {
        "id": "Uoi4I9iaCgzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7df8740c-f0d3-4ee9-c8f3-79dc2f8ab25a"
      },
      "id": "Uoi4I9iaCgzF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316144e6",
      "metadata": {
        "id": "316144e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1044ad77-a186-4d22-fab4-cd6055961bf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7394 sha256=a56a9a4d957a1ae34f7b4ca8d068ff02a3501554d90e35ddaa064279468a6a01\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Input, Dense, Dropout, Activation, Flatten, Conv1D, SimpleRNN\n",
        "from keras.layers import Layer, GlobalAveragePooling1D, AveragePooling1D, Convolution1D\n",
        "from keras.layers import MultiHeadAttention, LayerNormalization, Bidirectional, LSTM\n",
        "from keras import Model\n",
        "from keras.metrics import MeanSquaredError\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "!pip install GPUtil\n",
        "import GPUtil\n",
        "from scipy import stats\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score, average_precision_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preparation"
      ],
      "metadata": {
        "id": "NH1HHPJvmmNP"
      },
      "id": "NH1HHPJvmmNP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a36c276",
      "metadata": {
        "id": "0a36c276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97bb0c1f-ff9b-4083-ae47-0811b136a594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (15000, 34, 4)\n",
            "y_train shape: (15000, 1, 1)\n"
          ]
        }
      ],
      "source": [
        "def PREPROCESS_withoutCA(lines):\n",
        "    data_n = len(lines) - 1\n",
        "    SEQ = np.zeros((data_n, 34, 4), dtype=int)\n",
        "    label = np.zeros((data_n, 1, 1))\n",
        "\n",
        "    for l in range(1, data_n + 1):\n",
        "        data = lines[l].split(',')\n",
        "\n",
        "        y = float(data[2])\n",
        "        if y < 0:\n",
        "            label[l - 1, 0, 0] = 0\n",
        "        else:\n",
        "            label[l - 1, 0, 0] = y\n",
        "\n",
        "        seq = data[1]\n",
        "        for i in range(34):\n",
        "            if seq[i] in \"Aa\":\n",
        "                SEQ[l - 1, i, 0] = 1\n",
        "            elif seq[i] in \"Cc\":\n",
        "                SEQ[l - 1, i, 1] = 1\n",
        "            elif seq[i] in \"Gg\":\n",
        "                SEQ[l - 1, i, 2] = 1\n",
        "            elif seq[i] in \"Tt\":\n",
        "                SEQ[l - 1, i, 3] = 1\n",
        "\n",
        "    return SEQ, label\n",
        "\n",
        "FILE = open('/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-1-1.csv', \"r\")\n",
        "data = FILE.readlines()\n",
        "X_train, y_train = PREPROCESS_withoutCA(data)\n",
        "FILE.close()\n",
        "print(f'X_train shape: {X_train.shape}\\ny_train shape: {y_train.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluation on test datasets\n",
        "def evaluation_model(name, path):\n",
        "    print(f'Assessment for {name}:')\n",
        "    FILE = open(path, \"r\")\n",
        "    data = FILE.readlines()\n",
        "    X_test, y_test = PREPROCESS_withoutCA(data)\n",
        "    FILE.close()\n",
        "\n",
        "    pred_score = model.predict(X_test, batch_size=100, verbose=0)\n",
        "    y_test = y_test.reshape(len(y_test), 1)\n",
        "    res = stats.spearmanr(pred_score, y_test)\n",
        "    print('{:<15}{:>15}'.format('Spearman correlation', np.round(res.correlation, 4)))\n",
        "\n",
        "    true_type = [1 if item > np.percentile(y_test, 60) else 0 for item in y_test]\n",
        "    pre_type = [1 if item > np.percentile(pred_score, 60) else 0 for item in pred_score]\n",
        "\n",
        "    eval_funs = [accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, average_precision_score]\n",
        "    eval_fun_names = ['Accuracy', 'F1 score', 'Precision', 'Recall', 'ROC AUC', 'PR AUC']\n",
        "    eval_fun_types = [True, True, True, True, False, False]\n",
        "    for index_f, function in enumerate(eval_funs):\n",
        "        if eval_fun_types[index_f]:\n",
        "            score = np.round(function(true_type, pre_type), 4)\n",
        "        else:\n",
        "            score = np.round(function(true_type, pred_score.flatten()), 4)\n",
        "        print('{:<15}{:>15}'.format(eval_fun_names[index_f], score))\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "_-f2S3d94sVA"
      },
      "id": "_-f2S3d94sVA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ],
      "metadata": {
        "id": "ZcsGEmZX8Xvr"
      },
      "id": "ZcsGEmZX8Xvr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ccfe02e",
      "metadata": {
        "id": "0ccfe02e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f7f887-c0fb-465e-fa83-10202ae58111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 34, 4)]           0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 30, 80)            1680      \n",
            "                                                                 \n",
            " average_pooling1d (Average  (None, 15, 80)            0         \n",
            " Pooling1D)                                                      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1200)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1200)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 80)                96080     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 80)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 40)                3240      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 40)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 40)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 102681 (401.10 KB)\n",
            "Trainable params: 102681 (401.10 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def Seq_deepCpf1_model(input_shape):\n",
        "    Seq_deepCpf1_Input_SEQ = Input(shape=input_shape)\n",
        "\n",
        "    Seq_deepCpf1_C1 = Convolution1D(80, 5, activation='relu')(Seq_deepCpf1_Input_SEQ)\n",
        "    Seq_deepCpf1_P1 = AveragePooling1D(2)(Seq_deepCpf1_C1)\n",
        "    Seq_deepCpf1_F = Flatten()(Seq_deepCpf1_P1)\n",
        "    Seq_deepCpf1_DO1 = Dropout(0.3)(Seq_deepCpf1_F)\n",
        "    Seq_deepCpf1_D1 = Dense(80, activation='relu')(Seq_deepCpf1_DO1)\n",
        "    Seq_deepCpf1_DO2 = Dropout(0.3)(Seq_deepCpf1_D1)\n",
        "    Seq_deepCpf1_D2 = Dense(40, activation='relu')(Seq_deepCpf1_DO2)\n",
        "    Seq_deepCpf1_DO3 = Dropout(0.3)(Seq_deepCpf1_D2)\n",
        "    Seq_deepCpf1_D3 = Dense(40, activation='relu')(Seq_deepCpf1_DO3)\n",
        "    Seq_deepCpf1_DO4 = Dropout(0.3)(Seq_deepCpf1_D3)\n",
        "\n",
        "    Seq_deepCpf1_Output = Dense(1, activation='linear')(Seq_deepCpf1_DO4)\n",
        "    Seq_deepCpf1 = Model(inputs=[Seq_deepCpf1_Input_SEQ], outputs=[Seq_deepCpf1_Output])\n",
        "    return Seq_deepCpf1\n",
        "\n",
        "model = Seq_deepCpf1_model((34,4))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### training process\n",
        "\n",
        "# Fetch GPU details and record initial memory usage\n",
        "GPUs = GPUtil.getGPUs()\n",
        "gpu = GPUs[0]\n",
        "initial_memory = gpu.memoryUsed\n",
        "print(f\"Initial GPU Memory Usage: {initial_memory} MB\")\n",
        "\n",
        "\n",
        "model = Seq_deepCpf1_model((34,4))\n",
        "model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=[MeanSquaredError()])\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "\n",
        "# Record the start time\n",
        "start_time = time.time()\n",
        "# training\n",
        "print('Training...')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=256, callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "# Record the end time\n",
        "end_time = time.time()\n",
        "# Calculate the time\n",
        "time_taken = end_time - start_time\n",
        "print(f\"Training Time: {time_taken:.2f} seconds\")\n",
        "# After training, record the final memory usage and calculate the difference\n",
        "final_memory = gpu.memoryUsed\n",
        "print(f\"Final GPU Memory Usage: {final_memory} MB\")\n",
        "\n",
        "\n",
        "# save the model\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/Cas12/Seq_deepCpf1_weights.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDTbvjfw7FPC",
        "outputId": "c95f779c-ff75-4b74-fc51-db92721d6efe"
      },
      "id": "QDTbvjfw7FPC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial GPU Memory Usage: 2937.0 MB\n",
            "Training...\n",
            "Training Time: 11.89 seconds\n",
            "Final GPU Memory Usage: 2937.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### testing\n",
        "# load model\n",
        "model = Seq_deepCpf1_model((34, 4))\n",
        "model.load_weights('/content/drive/MyDrive/Colab Notebooks/Cas12/Seq_deepCpf1_weights.keras')\n",
        "\n",
        "\n",
        "# assessment\n",
        "evaluation_model('HT 1-2', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-1-2.csv')\n",
        "evaluation_model('HT 2', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-2.csv')\n",
        "evaluation_model('HT 3', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-3.csv')\n",
        "evaluation_model('HEK-lenti', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HEK-lenti.csv')\n",
        "evaluation_model('HEK-plasmid', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HEK-plasmid.csv')\n",
        "evaluation_model('HCT-plasmid', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HCT-plasmid.csv')\n",
        "evaluation_model('Kleinstiver 2016', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_Kleinstiver2016.csv')\n",
        "evaluation_model('Chari 2017', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_Chari2017.csv')"
      ],
      "metadata": {
        "id": "SPyf_ksuVRTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe9344b-84c7-49ef-88d6-6e2d5c7ef8c4"
      },
      "id": "SPyf_ksuVRTN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assessment for HT 1-2:\n",
            "Spearman correlation         0.7663\n",
            "Accuracy                0.7879\n",
            "F1 score                 0.735\n",
            "Precision                0.735\n",
            "Recall                   0.735\n",
            "ROC AUC                  0.874\n",
            "PR AUC                  0.7698\n",
            "\n",
            "\n",
            "Assessment for HT 2:\n",
            "Spearman correlation         0.7521\n",
            "Accuracy                0.7779\n",
            "F1 score                0.7224\n",
            "Precision               0.7224\n",
            "Recall                  0.7224\n",
            "ROC AUC                  0.864\n",
            "PR AUC                  0.7705\n",
            "\n",
            "\n",
            "Assessment for HT 3:\n",
            "Spearman correlation         0.5566\n",
            "Accuracy                0.7282\n",
            "F1 score                  0.66\n",
            "Precision                 0.66\n",
            "Recall                    0.66\n",
            "ROC AUC                 0.8054\n",
            "PR AUC                  0.7025\n",
            "\n",
            "\n",
            "Assessment for HEK-lenti:\n",
            "Spearman correlation         0.5574\n",
            "Accuracy                0.7297\n",
            "F1 score                 0.661\n",
            "Precision                0.661\n",
            "Recall                   0.661\n",
            "ROC AUC                 0.7448\n",
            "PR AUC                  0.6974\n",
            "\n",
            "\n",
            "Assessment for HEK-plasmid:\n",
            "Spearman correlation         0.6956\n",
            "Accuracy                0.7455\n",
            "F1 score                0.6818\n",
            "Precision               0.6818\n",
            "Recall                  0.6818\n",
            "ROC AUC                 0.8182\n",
            "PR AUC                   0.655\n",
            "\n",
            "\n",
            "Assessment for HCT-plasmid:\n",
            "Spearman correlation         0.5578\n",
            "Accuracy                0.6364\n",
            "F1 score                0.5385\n",
            "Precision               0.5385\n",
            "Recall                  0.5385\n",
            "ROC AUC                 0.7663\n",
            "PR AUC                  0.7262\n",
            "\n",
            "\n",
            "Assessment for Kleinstiver 2016:\n",
            "Spearman correlation         0.6755\n",
            "Accuracy                0.8182\n",
            "F1 score                0.7778\n",
            "Precision               0.7778\n",
            "Recall                  0.7778\n",
            "ROC AUC                 0.9145\n",
            "PR AUC                  0.8644\n",
            "\n",
            "\n",
            "Assessment for Chari 2017:\n",
            "Spearman correlation         0.6904\n",
            "Accuracy                0.7778\n",
            "F1 score                0.7143\n",
            "Precision               0.7143\n",
            "Recall                  0.7143\n",
            "ROC AUC                 0.8442\n",
            "PR AUC                  0.8099\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN+SimpleRNN"
      ],
      "metadata": {
        "id": "TAagwoK1LTN6"
      },
      "id": "TAagwoK1LTN6"
    },
    {
      "cell_type": "code",
      "source": [
        "def SimpleRNN_model(input_shape):\n",
        "    dropout_rate = 0.2\n",
        "    input = Input(shape=input_shape)\n",
        "\n",
        "    conv1 = Conv1D(128, 5, activation=\"relu\")(input)\n",
        "    pool1 = AveragePooling1D(2)(conv1)\n",
        "    drop1 = Dropout(dropout_rate)(pool1)\n",
        "\n",
        "    conv2 = Conv1D(128, 5, activation=\"relu\")(drop1)\n",
        "    pool2 = AveragePooling1D(2)(conv2)\n",
        "    drop2 = Dropout(dropout_rate)(pool2)\n",
        "\n",
        "    srnn1 = SimpleRNN(32,\n",
        "                      dropout=dropout_rate,\n",
        "                      activation=\"tanh\",\n",
        "                      return_sequences=True,\n",
        "                      kernel_regularizer=regularizers.l2(0.01))(drop2)\n",
        "    srnn2 = SimpleRNN(32,\n",
        "                      dropout=dropout_rate,\n",
        "                      activation=\"tanh\",\n",
        "                      return_sequences=True,\n",
        "                      kernel_regularizer=regularizers.l2(0.01))(srnn1)\n",
        "    avgpool = GlobalAveragePooling1D()(srnn2)\n",
        "\n",
        "    dense1 = Dense(512,\n",
        "                   kernel_regularizer=regularizers.l2(1e-4),\n",
        "                   bias_regularizer=regularizers.l2(1e-4),\n",
        "                   activation=\"relu\")(avgpool)\n",
        "    drop3 = Dropout(dropout_rate)(dense1)\n",
        "\n",
        "    dense2 = Dense(512,\n",
        "                   kernel_regularizer=regularizers.l2(1e-4),\n",
        "                   bias_regularizer=regularizers.l2(1e-4),\n",
        "                   activation=\"relu\")(drop3)\n",
        "    drop4 = Dropout(dropout_rate)(dense2)\n",
        "\n",
        "    dense3 = Dense(512,\n",
        "                   kernel_regularizer=regularizers.l2(1e-4),\n",
        "                   bias_regularizer=regularizers.l2(1e-4),\n",
        "                   activation=\"relu\")(drop4)\n",
        "    drop5 = Dropout(dropout_rate)(dense3)\n",
        "\n",
        "    output = Dense(1, activation='linear')(drop5)\n",
        "    model = Model(inputs=[input], outputs=[output])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = SimpleRNN_model((34,4))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "MPtllqIetgZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3976f696-a889-4d94-f7f7-41c7a4ad206a"
      },
      "id": "MPtllqIetgZ-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 34, 4)]           0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 30, 128)           2688      \n",
            "                                                                 \n",
            " average_pooling1d_1 (Avera  (None, 15, 128)           0         \n",
            " gePooling1D)                                                    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 15, 128)           0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 11, 128)           82048     \n",
            "                                                                 \n",
            " average_pooling1d_2 (Avera  (None, 5, 128)            0         \n",
            " gePooling1D)                                                    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 5, 128)            0         \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 5, 32)             5152      \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 5, 32)             2080      \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 32)                0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               16896     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 634689 (2.42 MB)\n",
            "Trainable params: 634689 (2.42 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### training process\n",
        "\n",
        "# Fetch GPU details and record initial memory usage\n",
        "GPUs = GPUtil.getGPUs()\n",
        "gpu = GPUs[0]\n",
        "initial_memory = gpu.memoryUsed\n",
        "print(f\"Initial GPU Memory Usage: {initial_memory} MB\")\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model = SimpleRNN_model((34,4))\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[MeanSquaredError()])\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "\n",
        "# Record the start time\n",
        "start_time = time.time()\n",
        "# training\n",
        "print('Training...')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=64, callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "# Record the end time\n",
        "end_time = time.time()\n",
        "# Calculate the time\n",
        "time_taken = end_time - start_time\n",
        "print(f\"Training Time: {time_taken:.2f} seconds\")\n",
        "# After training, record the final memory usage and calculate the difference\n",
        "final_memory = gpu.memoryUsed\n",
        "print(f\"Final GPU Memory Usage: {final_memory} MB\")\n",
        "\n",
        "\n",
        "# save the model\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/Cas12/SimpleRNN_Cpf1_weights.keras')"
      ],
      "metadata": {
        "id": "Apl-e2titgc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89ae853-7818-44b9-d9cc-1e2a00003bc0"
      },
      "id": "Apl-e2titgc7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial GPU Memory Usage: 1087.0 MB\n",
            "Training...\n",
            "Training Time: 622.39 seconds\n",
            "Final GPU Memory Usage: 1087.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### testing\n",
        "# load model\n",
        "model = SimpleRNN_model((34, 4))\n",
        "model.load_weights('/content/drive/MyDrive/Colab Notebooks/Cas12/SimpleRNN_Cpf1_weights.keras')\n",
        "\n",
        "\n",
        "# assessment\n",
        "evaluation_model('HT 1-2', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-1-2.csv')\n",
        "evaluation_model('HT 2', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-2.csv')\n",
        "evaluation_model('HT 3', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-3.csv')\n",
        "evaluation_model('HEK-lenti', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HEK-lenti.csv')\n",
        "evaluation_model('HEK-plasmid', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HEK-plasmid.csv')\n",
        "evaluation_model('HCT-plasmid', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HCT-plasmid.csv')\n",
        "evaluation_model('Kleinstiver 2016', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_Kleinstiver2016.csv')\n",
        "evaluation_model('Chari 2017', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_Chari2017.csv')"
      ],
      "metadata": {
        "id": "fJjXPBuvtgoP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbccb325-dc90-4f59-99f5-b6c20333f341"
      },
      "id": "fJjXPBuvtgoP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assessment for HT 1-2:\n",
            "Spearman correlation         0.7336\n",
            "Accuracy                0.7771\n",
            "F1 score                0.7215\n",
            "Precision               0.7215\n",
            "Recall                  0.7215\n",
            "ROC AUC                 0.8586\n",
            "PR AUC                  0.7515\n",
            "\n",
            "\n",
            "Assessment for HT 2:\n",
            "Spearman correlation         0.7344\n",
            "Accuracy                0.7685\n",
            "F1 score                0.7105\n",
            "Precision               0.7105\n",
            "Recall                  0.7105\n",
            "ROC AUC                 0.8509\n",
            "PR AUC                  0.7506\n",
            "\n",
            "\n",
            "Assessment for HT 3:\n",
            "Spearman correlation         0.5017\n",
            "Accuracy                0.6946\n",
            "F1 score                 0.618\n",
            "Precision                0.618\n",
            "Recall                   0.618\n",
            "ROC AUC                 0.7648\n",
            "PR AUC                  0.6437\n",
            "\n",
            "\n",
            "Assessment for HEK-lenti:\n",
            "Spearman correlation         0.5123\n",
            "Accuracy                0.6892\n",
            "F1 score                0.6102\n",
            "Precision               0.6102\n",
            "Recall                  0.6102\n",
            "ROC AUC                 0.7164\n",
            "PR AUC                  0.6672\n",
            "\n",
            "\n",
            "Assessment for HEK-plasmid:\n",
            "Spearman correlation         0.7073\n",
            "Accuracy                0.8182\n",
            "F1 score                0.7727\n",
            "Precision               0.7727\n",
            "Recall                  0.7727\n",
            "ROC AUC                 0.8278\n",
            "PR AUC                  0.7042\n",
            "\n",
            "\n",
            "Assessment for HCT-plasmid:\n",
            "Spearman correlation         0.5157\n",
            "Accuracy                 0.697\n",
            "F1 score                0.6154\n",
            "Precision               0.6154\n",
            "Recall                  0.6154\n",
            "ROC AUC                 0.7288\n",
            "PR AUC                  0.6216\n",
            "\n",
            "\n",
            "Assessment for Kleinstiver 2016:\n",
            "Spearman correlation         0.5715\n",
            "Accuracy                0.8182\n",
            "F1 score                0.7778\n",
            "Precision               0.7778\n",
            "Recall                  0.7778\n",
            "ROC AUC                 0.9316\n",
            "PR AUC                  0.9017\n",
            "\n",
            "\n",
            "Assessment for Chari 2017:\n",
            "Spearman correlation         0.6698\n",
            "Accuracy                0.7778\n",
            "F1 score                0.7143\n",
            "Precision               0.7143\n",
            "Recall                  0.7143\n",
            "ROC AUC                 0.8312\n",
            "PR AUC                  0.7949\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN+BiLSTM"
      ],
      "metadata": {
        "id": "HaA5HYZm9yy6"
      },
      "id": "HaA5HYZm9yy6"
    },
    {
      "cell_type": "code",
      "source": [
        "def BiLSTM_model(input_shape):\n",
        "    input = Input(shape=input_shape)\n",
        "\n",
        "    conv1 = Conv1D(128, 5, activation=\"relu\")(input)\n",
        "    pool1 = AveragePooling1D(2)(conv1)\n",
        "    drop1 = Dropout(0.1)(pool1)\n",
        "\n",
        "    conv2 = Conv1D(128, 5, activation=\"relu\")(drop1)\n",
        "    pool2 = AveragePooling1D(2)(conv2)\n",
        "    drop2 = Dropout(0.1)(pool2)\n",
        "\n",
        "    lstm1 = Bidirectional(LSTM(128,\n",
        "                               dropout=0.1,\n",
        "                               activation='tanh',\n",
        "                               return_sequences=True,\n",
        "                               kernel_regularizer=regularizers.l2(1e-4)))(drop2)\n",
        "    avgpool = GlobalAveragePooling1D()(lstm1)\n",
        "\n",
        "    dense1 = Dense(128,\n",
        "                   kernel_regularizer=regularizers.l2(1e-4),\n",
        "                   bias_regularizer=regularizers.l2(1e-4),\n",
        "                   activation=\"relu\")(avgpool)\n",
        "    drop3 = Dropout(0.1)(dense1)\n",
        "\n",
        "    dense2 = Dense(32,\n",
        "                   kernel_regularizer=regularizers.l2(1e-4),\n",
        "                   bias_regularizer=regularizers.l2(1e-4),\n",
        "                   activation=\"relu\")(drop3)\n",
        "    drop4 = Dropout(0.1)(dense2)\n",
        "\n",
        "    dense3 = Dense(32,\n",
        "                   kernel_regularizer=regularizers.l2(1e-4),\n",
        "                   bias_regularizer=regularizers.l2(1e-4),\n",
        "                   activation=\"relu\")(drop4)\n",
        "    drop5 = Dropout(0.1)(dense3)\n",
        "\n",
        "    output = Dense(1, activation=\"linear\")(drop5)\n",
        "\n",
        "    model = Model(inputs=[input], outputs=[output])\n",
        "    return model\n",
        "\n",
        "model = BiLSTM_model((34,4))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "4SiN1OU1Lo5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5e61bd-5eee-40d1-ab66-791e3cc7e74e"
      },
      "id": "4SiN1OU1Lo5O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 34, 4)]           0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 30, 128)           2688      \n",
            "                                                                 \n",
            " average_pooling1d (Average  (None, 15, 128)           0         \n",
            " Pooling1D)                                                      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 128)           0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 128)           82048     \n",
            "                                                                 \n",
            " average_pooling1d_1 (Avera  (None, 5, 128)            0         \n",
            " gePooling1D)                                                    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 5, 128)            0         \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 5, 256)            263168    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 256)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 386017 (1.47 MB)\n",
            "Trainable params: 386017 (1.47 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### training process\n",
        "\n",
        "# Fetch GPU details and record initial memory usage\n",
        "GPUs = GPUtil.getGPUs()\n",
        "gpu = GPUs[0]\n",
        "initial_memory = gpu.memoryUsed\n",
        "print(f\"Initial GPU Memory Usage: {initial_memory} MB\")\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model = BiLSTM_model((34,4))\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[MeanSquaredError()])\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "\n",
        "# Record the start time\n",
        "start_time = time.time()\n",
        "# training\n",
        "print('Training...')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=256, callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "# Record the end time\n",
        "end_time = time.time()\n",
        "# Calculate the time\n",
        "time_taken = end_time - start_time\n",
        "print(f\"Training Time: {time_taken:.2f} seconds\")\n",
        "# After training, record the final memory usage and calculate the difference\n",
        "final_memory = gpu.memoryUsed\n",
        "print(f\"Final GPU Memory Usage: {final_memory} MB\")\n",
        "\n",
        "\n",
        "# save the model\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/Cas12/BiLSTM_Cpf1_weights.keras')"
      ],
      "metadata": {
        "id": "II578u-v-aAO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f70065-607f-413a-f5e1-15b2da1b6530"
      },
      "id": "II578u-v-aAO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial GPU Memory Usage: 2937.0 MB\n",
            "Training...\n",
            "Training Time: 72.44 seconds\n",
            "Final GPU Memory Usage: 2937.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### testing\n",
        "# load model\n",
        "model = BiLSTM_model((34, 4))\n",
        "model.load_weights('/content/drive/MyDrive/Colab Notebooks/Cas12/BiLSTM_Cpf1_weights.keras')\n",
        "\n",
        "\n",
        "# assessment\n",
        "evaluation_model('HT 1-2', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-1-2.csv')\n",
        "evaluation_model('HT 2', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-2.csv')\n",
        "evaluation_model('HT 3', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-3.csv')\n",
        "evaluation_model('HEK-lenti', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HEK-lenti.csv')\n",
        "evaluation_model('HEK-plasmid', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HEK-plasmid.csv')\n",
        "evaluation_model('HCT-plasmid', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HCT-plasmid.csv')\n",
        "evaluation_model('Kleinstiver 2016', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_Kleinstiver2016.csv')\n",
        "evaluation_model('Chari 2017', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_Chari2017.csv')"
      ],
      "metadata": {
        "id": "2z50ZUP4n11z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7b5919d-774e-47f4-e4bd-85225fae8e78"
      },
      "id": "2z50ZUP4n11z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assessment for HT 1-2:\n",
            "Spearman correlation         0.7711\n",
            "Accuracy                0.8003\n",
            "F1 score                0.7505\n",
            "Precision               0.7505\n",
            "Recall                  0.7505\n",
            "ROC AUC                  0.878\n",
            "PR AUC                  0.7689\n",
            "\n",
            "\n",
            "Assessment for HT 2:\n",
            "Spearman correlation         0.7587\n",
            "Accuracy                0.7773\n",
            "F1 score                0.7215\n",
            "Precision               0.7215\n",
            "Recall                  0.7215\n",
            "ROC AUC                 0.8651\n",
            "PR AUC                  0.7676\n",
            "\n",
            "\n",
            "Assessment for HT 3:\n",
            "Spearman correlation         0.5714\n",
            "Accuracy                0.7298\n",
            "F1 score                 0.662\n",
            "Precision                0.662\n",
            "Recall                   0.662\n",
            "ROC AUC                 0.8049\n",
            "PR AUC                  0.6943\n",
            "\n",
            "\n",
            "Assessment for HEK-lenti:\n",
            "Spearman correlation         0.5883\n",
            "Accuracy                0.7162\n",
            "F1 score                0.6441\n",
            "Precision               0.6441\n",
            "Recall                  0.6441\n",
            "ROC AUC                 0.7484\n",
            "PR AUC                  0.6963\n",
            "\n",
            "\n",
            "Assessment for HEK-plasmid:\n",
            "Spearman correlation         0.7286\n",
            "Accuracy                0.8182\n",
            "F1 score                0.7727\n",
            "Precision               0.7727\n",
            "Recall                  0.7727\n",
            "ROC AUC                  0.832\n",
            "PR AUC                   0.695\n",
            "\n",
            "\n",
            "Assessment for HCT-plasmid:\n",
            "Spearman correlation         0.5671\n",
            "Accuracy                0.7273\n",
            "F1 score                0.6538\n",
            "Precision               0.6538\n",
            "Recall                  0.6538\n",
            "ROC AUC                 0.7635\n",
            "PR AUC                  0.6944\n",
            "\n",
            "\n",
            "Assessment for Kleinstiver 2016:\n",
            "Spearman correlation         0.6653\n",
            "Accuracy                0.9091\n",
            "F1 score                0.8889\n",
            "Precision               0.8889\n",
            "Recall                  0.8889\n",
            "ROC AUC                 0.9402\n",
            "PR AUC                  0.8969\n",
            "\n",
            "\n",
            "Assessment for Chari 2017:\n",
            "Spearman correlation         0.6925\n",
            "Accuracy                0.7778\n",
            "F1 score                0.7143\n",
            "Precision               0.7143\n",
            "Recall                  0.7143\n",
            "ROC AUC                 0.8312\n",
            "PR AUC                  0.7742\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN+BiLSTM+MultiHeadAttention"
      ],
      "metadata": {
        "id": "8CadDDd0LrXm"
      },
      "id": "8CadDDd0LrXm"
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, sequence_len=None, embedding_dim=None,**kwargs):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.sequence_len = sequence_len\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        position_embedding = np.array([\n",
        "            [pos / np.power(10000, 2. * i / self.embedding_dim) for i in range(self.embedding_dim)]\n",
        "            for pos in range(self.sequence_len)])\n",
        "\n",
        "        position_embedding[:, 0::2] = np.sin(position_embedding[:, 0::2])  # dim 2i\n",
        "        position_embedding[:, 1::2] = np.cos(position_embedding[:, 1::2])  # dim 2i+1\n",
        "        position_embedding = tf.cast(position_embedding, dtype=tf.float32)\n",
        "\n",
        "        return position_embedding+x\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'sequence_len' : self.sequence_len,\n",
        "            'embedding_dim' : self.embedding_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "def MultiHeadAttention_model(input_shape):\n",
        "    input = Input(shape=input_shape)\n",
        "\n",
        "    conv1 = Conv1D(512, 5, activation=\"relu\")(input)\n",
        "    pool1 = AveragePooling1D(2)(conv1)\n",
        "    drop1 = Dropout(0.4)(pool1)\n",
        "\n",
        "    conv2 = Conv1D(512, 5, activation=\"relu\")(drop1)\n",
        "    pool2 = AveragePooling1D(2)(conv2)\n",
        "    drop2 = Dropout(0.4)(pool2)\n",
        "\n",
        "    lstm = Bidirectional(LSTM(16,\n",
        "                               dropout=0.5,\n",
        "                               activation='tanh',\n",
        "                               return_sequences=True,\n",
        "                               kernel_regularizer=regularizers.l2(0.01)))(drop2)\n",
        "\n",
        "    pos_embedding = PositionalEncoding(sequence_len=int(((34-5+1)/2-5+1)/2), embedding_dim=2*16)(lstm)\n",
        "    atten = MultiHeadAttention(num_heads=2,\n",
        "                               key_dim=32,\n",
        "                               dropout=0.5,\n",
        "                               kernel_regularizer=regularizers.l2(0.01))(pos_embedding, pos_embedding)\n",
        "\n",
        "    flat = Flatten()(atten)\n",
        "\n",
        "    dense1 = Dense(256,\n",
        "                   kernel_regularizer=regularizers.l2(1e-4),\n",
        "                   bias_regularizer=regularizers.l2(1e-4),\n",
        "                   activation=\"relu\")(flat)\n",
        "    drop3 = Dropout(0.2)(dense1)\n",
        "\n",
        "    dense2 = Dense(128,\n",
        "                   kernel_regularizer=regularizers.l2(1e-4),\n",
        "                   bias_regularizer=regularizers.l2(1e-4),\n",
        "                   activation=\"relu\")(drop3)\n",
        "    drop4 = Dropout(0.2)(dense2)\n",
        "\n",
        "    dense3 = Dense(512,\n",
        "                   kernel_regularizer=regularizers.l2(1e-4),\n",
        "                   bias_regularizer=regularizers.l2(1e-4),\n",
        "                   activation=\"relu\")(drop4)\n",
        "    drop5 = Dropout(0.2)(dense3)\n",
        "\n",
        "    output = Dense(1, activation=\"linear\")(drop5)\n",
        "\n",
        "    model = Model(inputs=[input], outputs=[output])\n",
        "    return model\n",
        "\n",
        "model = MultiHeadAttention_model((34,4))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "kZ86fxQ7Luqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa6c626c-4920-4396-9b4e-ad492701f15a"
      },
      "id": "kZ86fxQ7Luqa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)        [(None, 34, 4)]              0         []                            \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)           (None, 30, 512)              10752     ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " average_pooling1d_5 (Avera  (None, 15, 512)              0         ['conv1d_5[0][0]']            \n",
            " gePooling1D)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)        (None, 15, 512)              0         ['average_pooling1d_5[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)           (None, 11, 512)              1311232   ['dropout_14[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling1d_6 (Avera  (None, 5, 512)               0         ['conv1d_6[0][0]']            \n",
            " gePooling1D)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)        (None, 5, 512)               0         ['average_pooling1d_6[0][0]'] \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirecti  (None, 5, 32)                67712     ['dropout_15[0][0]']          \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " positional_encoding (Posit  (None, 5, 32)                0         ['bidirectional_1[0][0]']     \n",
            " ionalEncoding)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention (Mult  (None, 5, 32)                8416      ['positional_encoding[0][0]', \n",
            " iHeadAttention)                                                     'positional_encoding[0][0]'] \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 160)                  0         ['multi_head_attention[0][0]']\n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 256)                  41216     ['flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)        (None, 256)                  0         ['dense_12[0][0]']            \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 128)                  32896     ['dropout_16[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)        (None, 128)                  0         ['dense_13[0][0]']            \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, 512)                  66048     ['dropout_17[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)        (None, 512)                  0         ['dense_14[0][0]']            \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, 1)                    513       ['dropout_18[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1538785 (5.87 MB)\n",
            "Trainable params: 1538785 (5.87 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### training process\n",
        "\n",
        "# Fetch GPU details and record initial memory usage\n",
        "GPUs = GPUtil.getGPUs()\n",
        "gpu = GPUs[0]\n",
        "initial_memory = gpu.memoryUsed\n",
        "print(f\"Initial GPU Memory Usage: {initial_memory} MB\")\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model = MultiHeadAttention_model((34,4))\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[MeanSquaredError()])\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "\n",
        "# Record the start time\n",
        "start_time = time.time()\n",
        "# training\n",
        "print('Training...')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "# Record the end time\n",
        "end_time = time.time()\n",
        "# Calculate the time\n",
        "time_taken = end_time - start_time\n",
        "print(f\"Training Time: {time_taken:.2f} seconds\")\n",
        "# After training, record the final memory usage and calculate the difference\n",
        "final_memory = gpu.memoryUsed\n",
        "print(f\"Final GPU Memory Usage: {final_memory} MB\")\n",
        "\n",
        "\n",
        "# save the model\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/Cas12/MultiHeadAttention_Cpf1_weights.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyLw8seeN4Es",
        "outputId": "346bc520-21d6-48be-e88c-53a57a48fcfc"
      },
      "id": "fyLw8seeN4Es",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial GPU Memory Usage: 759.0 MB\n",
            "Training...\n",
            "Training Time: 748.73 seconds\n",
            "Final GPU Memory Usage: 759.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### testing\n",
        "# load model\n",
        "model = MultiHeadAttention_model((34, 4))\n",
        "model.load_weights('/content/drive/MyDrive/Colab Notebooks/Cas12/MultiHeadAttention_Cpf1_weights.keras')\n",
        "\n",
        "# assessment\n",
        "evaluation_model('HT 1-2', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-1-2.csv')\n",
        "evaluation_model('HT 2', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-2.csv')\n",
        "evaluation_model('HT 3', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-3.csv')\n",
        "evaluation_model('HEK-lenti', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HEK-lenti.csv')\n",
        "evaluation_model('HEK-plasmid', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HEK-plasmid.csv')\n",
        "evaluation_model('HCT-plasmid', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HCT-plasmid.csv')\n",
        "evaluation_model('Kleinstiver 2016', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_Kleinstiver2016.csv')\n",
        "evaluation_model('Chari 2017', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_Chari2017.csv')"
      ],
      "metadata": {
        "id": "H70ORFupLo_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37d389ae-d0a7-4c95-ea01-4ceb7f14c68f"
      },
      "id": "H70ORFupLo_o",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assessment for HT 1-2:\n",
            "Spearman correlation         0.7383\n",
            "Accuracy                0.7678\n",
            "F1 score                0.7099\n",
            "Precision               0.7099\n",
            "Recall                  0.7099\n",
            "ROC AUC                 0.8619\n",
            "PR AUC                  0.7579\n",
            "\n",
            "\n",
            "Assessment for HT 2:\n",
            "Spearman correlation         0.7282\n",
            "Accuracy                0.7631\n",
            "F1 score                0.7038\n",
            "Precision               0.7038\n",
            "Recall                  0.7038\n",
            "ROC AUC                 0.8478\n",
            "PR AUC                   0.739\n",
            "\n",
            "\n",
            "Assessment for HT 3:\n",
            "Spearman correlation         0.4664\n",
            "Accuracy                0.6978\n",
            "F1 score                 0.622\n",
            "Precision                0.622\n",
            "Recall                   0.622\n",
            "ROC AUC                 0.7532\n",
            "PR AUC                  0.6228\n",
            "\n",
            "\n",
            "Assessment for HEK-lenti:\n",
            "Spearman correlation         0.5428\n",
            "Accuracy                0.6757\n",
            "F1 score                0.5932\n",
            "Precision               0.5932\n",
            "Recall                  0.5932\n",
            "ROC AUC                 0.7341\n",
            "PR AUC                  0.6466\n",
            "\n",
            "\n",
            "Assessment for HEK-plasmid:\n",
            "Spearman correlation         0.6949\n",
            "Accuracy                0.7455\n",
            "F1 score                0.6818\n",
            "Precision               0.6818\n",
            "Recall                  0.6818\n",
            "ROC AUC                 0.7975\n",
            "PR AUC                  0.6343\n",
            "\n",
            "\n",
            "Assessment for HCT-plasmid:\n",
            "Spearman correlation          0.452\n",
            "Accuracy                 0.697\n",
            "F1 score                0.6154\n",
            "Precision               0.6154\n",
            "Recall                  0.6154\n",
            "ROC AUC                 0.6971\n",
            "PR AUC                  0.5609\n",
            "\n",
            "\n",
            "Assessment for Kleinstiver 2016:\n",
            "Spearman correlation          0.723\n",
            "Accuracy                0.9091\n",
            "F1 score                0.8889\n",
            "Precision               0.8889\n",
            "Recall                  0.8889\n",
            "ROC AUC                 0.9573\n",
            "PR AUC                   0.946\n",
            "\n",
            "\n",
            "Assessment for Chari 2017:\n",
            "Spearman correlation          0.612\n",
            "Accuracy                0.6667\n",
            "F1 score                0.5714\n",
            "Precision               0.5714\n",
            "Recall                  0.5714\n",
            "ROC AUC                 0.7922\n",
            "PR AUC                  0.6965\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN+BiLSTM+Transformer"
      ],
      "metadata": {
        "id": "dfo2PmHGerAm"
      },
      "id": "dfo2PmHGerAm"
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self, sequence_len=None, embedding_dim=None,**kwargs):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.sequence_len = sequence_len\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        position_embedding = np.array([\n",
        "            [pos / np.power(10000, 2. * i / self.embedding_dim) for i in range(self.embedding_dim)]\n",
        "            for pos in range(self.sequence_len)])\n",
        "\n",
        "        position_embedding[:, 0::2] = np.sin(position_embedding[:, 0::2])  # dim 2i\n",
        "        position_embedding[:, 1::2] = np.cos(position_embedding[:, 1::2])  # dim 2i+1\n",
        "        position_embedding = tf.cast(position_embedding, dtype=tf.float32)\n",
        "\n",
        "        return position_embedding+x\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'sequence_len' : self.sequence_len,\n",
        "            'embedding_dim' : self.embedding_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate):\n",
        "        # embed_dim: Embedding size for each token\n",
        "        # num_heads: Number of attention heads\n",
        "        # ff_dim: Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [Dense(ff_dim, activation=\"relu\"),\n",
        "             Dense(embed_dim)]\n",
        "        )\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-3)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-3)\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "\n",
        "def Transformer_model(input_shape):\n",
        "    input = Input(shape=input_shape)\n",
        "    conv1 = Conv1D(512, 5, activation=\"relu\")(input)\n",
        "    pool1 = AveragePooling1D(2)(conv1)\n",
        "    drop1 = Dropout(0.4)(pool1)\n",
        "\n",
        "    conv2 = Conv1D(512, 5, activation=\"relu\")(drop1)\n",
        "    pool2 = AveragePooling1D(2)(conv2)\n",
        "    drop2 = Dropout(0.4)(pool2)\n",
        "\n",
        "    lstm1 = Bidirectional(LSTM(32,\n",
        "                               dropout=0.2,\n",
        "                               activation='tanh',\n",
        "                               return_sequences=True,\n",
        "                               kernel_regularizer=regularizers.l2(0.01)))(drop2)\n",
        "    lstm2 = Bidirectional(LSTM(64,\n",
        "                               dropout=0.2,\n",
        "                               activation='tanh',\n",
        "                               return_sequences=True,\n",
        "                               kernel_regularizer=regularizers.l2(0.01)))(lstm1)\n",
        "\n",
        "    pos_embedding = PositionalEncoding(sequence_len=int(((34-5+1)/2-5+1)/2), embedding_dim=2*64)(lstm2)\n",
        "    trans = TransformerBlock(embed_dim=2*64, num_heads=2, ff_dim=256, dropout_rate=0.3)(pos_embedding)\n",
        "    avgpool = GlobalAveragePooling1D()(trans)\n",
        "\n",
        "    dense1 = Dense(512,\n",
        "                   kernel_regularizer=regularizers.l2(1e-4),\n",
        "                   bias_regularizer=regularizers.l2(1e-4),\n",
        "                   activation=\"relu\")(avgpool)\n",
        "    drop3 = Dropout(0.1)(dense1)\n",
        "\n",
        "    dense2 = Dense(256,\n",
        "                   kernel_regularizer=regularizers.l2(1e-4),\n",
        "                   bias_regularizer=regularizers.l2(1e-4),\n",
        "                   activation=\"relu\")(drop3)\n",
        "    drop4 = Dropout(0.1)(dense2)\n",
        "\n",
        "    dense3 = Dense(16,\n",
        "                   kernel_regularizer=regularizers.l2(1e-4),\n",
        "                   bias_regularizer=regularizers.l2(1e-4),\n",
        "                   activation=\"relu\")(drop4)\n",
        "    drop5 = Dropout(0.1)(dense3)\n",
        "\n",
        "    output = Dense(1, activation=\"linear\")(drop5)\n",
        "\n",
        "    model = Model(inputs=[input], outputs=[output])\n",
        "    return model\n",
        "\n",
        "model = Transformer_model((34,4))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RtwMdvQMdUJ",
        "outputId": "aa0dfa08-cdd1-47a2-e441-8d128087d05d"
      },
      "id": "5RtwMdvQMdUJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 34, 4)]           0         \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 30, 512)           10752     \n",
            "                                                                 \n",
            " average_pooling1d_7 (Avera  (None, 15, 512)           0         \n",
            " gePooling1D)                                                    \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 15, 512)           0         \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, 11, 512)           1311232   \n",
            "                                                                 \n",
            " average_pooling1d_8 (Avera  (None, 5, 512)            0         \n",
            " gePooling1D)                                                    \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 5, 512)            0         \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 5, 64)             139520    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 5, 128)            66048     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " positional_encoding_1 (Pos  (None, 5, 128)            0         \n",
            " itionalEncoding)                                                \n",
            "                                                                 \n",
            " transformer_block (Transfo  (None, 5, 128)            198400    \n",
            " rmerBlock)                                                      \n",
            "                                                                 \n",
            " global_average_pooling1d_2  (None, 128)               0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 512)               66048     \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 16)                4112      \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1927457 (7.35 MB)\n",
            "Trainable params: 1927457 (7.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### training process\n",
        "\n",
        "# Fetch GPU details and record initial memory usage\n",
        "GPUs = GPUtil.getGPUs()\n",
        "gpu = GPUs[0]\n",
        "initial_memory = gpu.memoryUsed\n",
        "print(f\"Initial GPU Memory Usage: {initial_memory} MB\")\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model = Transformer_model((34,4))\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[MeanSquaredError()])\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "\n",
        "# Record the start time\n",
        "start_time = time.time()\n",
        "# training\n",
        "print('Training...')\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=64, callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "# Record the end time\n",
        "end_time = time.time()\n",
        "# Calculate the time\n",
        "time_taken = end_time - start_time\n",
        "print(f\"Training Time: {time_taken:.2f} seconds\")\n",
        "# After training, record the final memory usage and calculate the difference\n",
        "final_memory = gpu.memoryUsed\n",
        "print(f\"Final GPU Memory Usage: {final_memory} MB\")\n",
        "\n",
        "\n",
        "# save the model\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/Cas12/Transformer_Cpf1_weights.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnlPVbpENf6-",
        "outputId": "caa1e85a-4759-4fc3-b7c1-7506136c240d"
      },
      "id": "JnlPVbpENf6-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial GPU Memory Usage: 3833.0 MB\n",
            "Training...\n",
            "Training Time: 579.60 seconds\n",
            "Final GPU Memory Usage: 3833.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### testing\n",
        "# load model\n",
        "model = Transformer_model((34, 4))\n",
        "model.load_weights('/content/drive/MyDrive/Colab Notebooks/Cas12/Transformer_Cpf1_weights.keras')\n",
        "\n",
        "\n",
        "# assessment\n",
        "evaluation_model('HT 1-2', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-1-2.csv')\n",
        "evaluation_model('HT 2', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-2.csv')\n",
        "evaluation_model('HT 3', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HT-3.csv')\n",
        "evaluation_model('HEK-lenti', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HEK-lenti.csv')\n",
        "evaluation_model('HEK-plasmid', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HEK-plasmid.csv')\n",
        "evaluation_model('HCT-plasmid', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_HCT-plasmid.csv')\n",
        "evaluation_model('Kleinstiver 2016', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_Kleinstiver2016.csv')\n",
        "evaluation_model('Chari 2017', '/content/drive/MyDrive/Colab Notebooks/Cas12/data/input_Chari2017.csv')"
      ],
      "metadata": {
        "id": "Y0MGgVGSNyST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae214e9e-1a3d-42ea-a3e3-b25d52ac349f"
      },
      "id": "Y0MGgVGSNyST",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assessment for HT 1-2:\n",
            "Spearman correlation         0.7384\n",
            "Accuracy                0.7833\n",
            "F1 score                0.7292\n",
            "Precision               0.7292\n",
            "Recall                  0.7292\n",
            "ROC AUC                 0.8603\n",
            "PR AUC                  0.7453\n",
            "\n",
            "\n",
            "Assessment for HT 2:\n",
            "Spearman correlation         0.7299\n",
            "Accuracy                0.7631\n",
            "F1 score                0.7038\n",
            "Precision               0.7038\n",
            "Recall                  0.7038\n",
            "ROC AUC                 0.8488\n",
            "PR AUC                  0.7424\n",
            "\n",
            "\n",
            "Assessment for HT 3:\n",
            "Spearman correlation         0.4787\n",
            "Accuracy                0.6978\n",
            "F1 score                 0.622\n",
            "Precision                0.622\n",
            "Recall                   0.622\n",
            "ROC AUC                 0.7543\n",
            "PR AUC                  0.6432\n",
            "\n",
            "\n",
            "Assessment for HEK-lenti:\n",
            "Spearman correlation         0.5639\n",
            "Accuracy                0.6757\n",
            "F1 score                0.5932\n",
            "Precision               0.5932\n",
            "Recall                  0.5932\n",
            "ROC AUC                 0.7298\n",
            "PR AUC                  0.6557\n",
            "\n",
            "\n",
            "Assessment for HEK-plasmid:\n",
            "Spearman correlation         0.7201\n",
            "Accuracy                0.7818\n",
            "F1 score                0.7273\n",
            "Precision               0.7273\n",
            "Recall                  0.7273\n",
            "ROC AUC                 0.8251\n",
            "PR AUC                  0.7501\n",
            "\n",
            "\n",
            "Assessment for HCT-plasmid:\n",
            "Spearman correlation         0.4643\n",
            "Accuracy                0.7273\n",
            "F1 score                0.6538\n",
            "Precision               0.6538\n",
            "Recall                  0.6538\n",
            "ROC AUC                 0.7087\n",
            "PR AUC                  0.6347\n",
            "\n",
            "\n",
            "Assessment for Kleinstiver 2016:\n",
            "Spearman correlation         0.5206\n",
            "Accuracy                0.8182\n",
            "F1 score                0.7778\n",
            "Precision               0.7778\n",
            "Recall                  0.7778\n",
            "ROC AUC                 0.9145\n",
            "PR AUC                  0.8734\n",
            "\n",
            "\n",
            "Assessment for Chari 2017:\n",
            "Spearman correlation         0.5377\n",
            "Accuracy                0.6667\n",
            "F1 score                0.5714\n",
            "Precision               0.5714\n",
            "Recall                  0.5714\n",
            "ROC AUC                 0.8182\n",
            "PR AUC                  0.8156\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}